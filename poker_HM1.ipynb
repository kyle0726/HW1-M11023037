{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout,LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import backend as K \n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "import talos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_error(y_true, y_pred):\n",
    "    return K.mean(K.abs(y_pred - y_true), axis=-1)\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    diff = K.abs((y_true - y_pred) / K.clip(K.abs(y_true),\n",
    "                                            K.epsilon(),\n",
    "                                            None))\n",
    "    return 100. * K.mean(diff, axis=-1)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(lt):\n",
    "    for i in lt.columns:\n",
    "        if((i == 'S1') or (i == 'CLASS')):\n",
    "            continue\n",
    "        lt[i] = (lt[i] - lt[i].min())/(lt[i] - lt[i].min()).max()\n",
    "    return lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "poker = pd.read_csv('poker-hand-testing.data', low_memory=False)\n",
    "poker.columns = ['S1','C1','S2','C2','S3','C3','S4','C4','S5','C5','CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "poker['S1'] = labelencoder.fit_transform(poker['S1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_y = poker['CLASS']\n",
    "regression_x = poker.drop(columns=['CLASS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rx, test_rx, train_ry, test_ry = train_test_split(regression_x, regression_y,\n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=0)\n",
    "test_ry = test_ry.values\n",
    "test_ry = [float(test_ry[i]) for i in range(len(test_ry))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_y = poker['S1']\n",
    "classification_x = poker.drop(columns=['S1'])\n",
    "train_cx, test_cx, train_cy, test_cy = train_test_split(classification_x, classification_y,\n",
    "                                                    test_size=0.33, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cy = test_cy.values\n",
    "test_cy = [float(test_cy[i]) for i in range(len(test_cy))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talos_regression_best(x_train, y_train, x_val, y_val, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "#     sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(loss = 'mse', optimizer = params['optimizer'], metrics = ['mae'])\n",
    "    out = model.fit(x_train, y_train,\n",
    "                              epochs=params['epochs'],  \n",
    "                              batch_size=params['batch_size'],\n",
    "                              validation_split=0.1)\n",
    "    return out,model\n",
    "\n",
    "def build_regression_model(x, y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "#     sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    \n",
    "    model.compile(loss = 'mae', optimizer = 'SGD', metrics = ['mae'])\n",
    "    model_result = model.fit(x, y,\n",
    "                              epochs=200,  \n",
    "                              batch_size=32,\n",
    "                              validation_split=0.1)\n",
    "    loss,mae = model.evaluate(x, y, verbose=1)\n",
    "    print(mae)\n",
    "    print('Test loss:', loss)\n",
    "    print('Test accuracy:', mae)\n",
    "    plt.plot(model_result.history['loss'])\n",
    "    plt.plot(model_result.history['mae'])\n",
    "    plt.plot(model_result.history['val_loss'])\n",
    "    plt.plot(model_result.history['val_mae'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['loss', 'mae','val_loss', 'val_mae'], loc='upper left') \n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18844/18844 [==============================] - 25s 1ms/step - loss: 0.2307 - mae: 0.2307 - val_loss: 0.3065 - val_mae: 0.3065\n",
      "Epoch 2/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0588 - mae: 0.0588 - val_loss: 0.3284 - val_mae: 0.3284\n",
      "Epoch 3/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0436 - mae: 0.0436 - val_loss: 0.3610 - val_mae: 0.3610\n",
      "Epoch 4/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0378 - mae: 0.0378 - val_loss: 0.4032 - val_mae: 0.4032\n",
      "Epoch 5/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0342 - mae: 0.0342 - val_loss: 0.3370 - val_mae: 0.3370\n",
      "Epoch 6/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0315 - mae: 0.0315 - val_loss: 0.3716 - val_mae: 0.3716\n",
      "Epoch 7/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0298 - mae: 0.0298 - val_loss: 0.3437 - val_mae: 0.3437\n",
      "Epoch 8/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0284 - mae: 0.0284 - val_loss: 0.3390 - val_mae: 0.3390\n",
      "Epoch 9/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0270 - mae: 0.0270 - val_loss: 0.2890 - val_mae: 0.2890\n",
      "Epoch 10/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0260 - mae: 0.0260 - val_loss: 0.3095 - val_mae: 0.3095\n",
      "Epoch 11/200\n",
      "18844/18844 [==============================] - 24s 1ms/step - loss: 0.0253 - mae: 0.0253 - val_loss: 0.3305 - val_mae: 0.3305\n",
      "Epoch 12/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0244 - mae: 0.0244 - val_loss: 0.3174 - val_mae: 0.3174\n",
      "Epoch 13/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0237 - mae: 0.0237 - val_loss: 0.3076 - val_mae: 0.3076\n",
      "Epoch 14/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0230 - mae: 0.0230 - val_loss: 0.3148 - val_mae: 0.3148\n",
      "Epoch 15/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0223 - mae: 0.0223 - val_loss: 0.2907 - val_mae: 0.2907\n",
      "Epoch 16/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0213 - mae: 0.0213 - val_loss: 0.2777 - val_mae: 0.2777\n",
      "Epoch 17/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0200 - mae: 0.0200 - val_loss: 0.2879 - val_mae: 0.2879\n",
      "Epoch 18/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0191 - mae: 0.0191 - val_loss: 0.2788 - val_mae: 0.2788\n",
      "Epoch 19/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0187 - mae: 0.0187 - val_loss: 0.2660 - val_mae: 0.2660\n",
      "Epoch 20/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0183 - mae: 0.0183 - val_loss: 0.2684 - val_mae: 0.2684\n",
      "Epoch 21/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0179 - mae: 0.0179 - val_loss: 0.2488 - val_mae: 0.2488\n",
      "Epoch 22/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0175 - mae: 0.0175 - val_loss: 0.2445 - val_mae: 0.2445\n",
      "Epoch 23/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0173 - mae: 0.0173 - val_loss: 0.2445 - val_mae: 0.2445\n",
      "Epoch 24/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0168 - mae: 0.0168 - val_loss: 0.2424 - val_mae: 0.2424\n",
      "Epoch 25/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0166 - mae: 0.0166 - val_loss: 0.2512 - val_mae: 0.2512\n",
      "Epoch 26/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0163 - mae: 0.0163 - val_loss: 0.2473 - val_mae: 0.2473\n",
      "Epoch 27/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0164 - mae: 0.0164 - val_loss: 0.2348 - val_mae: 0.2348\n",
      "Epoch 28/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.2318 - val_mae: 0.2318\n",
      "Epoch 29/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0158 - mae: 0.0158 - val_loss: 0.2241 - val_mae: 0.2241\n",
      "Epoch 30/200\n",
      "18844/18844 [==============================] - 24s 1ms/step - loss: 0.0156 - mae: 0.0156 - val_loss: 0.2219 - val_mae: 0.2219\n",
      "Epoch 31/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0155 - mae: 0.0155 - val_loss: 0.2314 - val_mae: 0.2314\n",
      "Epoch 32/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.2139 - val_mae: 0.2139\n",
      "Epoch 33/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0153 - mae: 0.0153 - val_loss: 0.2194 - val_mae: 0.2194\n",
      "Epoch 34/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0152 - mae: 0.0152 - val_loss: 0.2190 - val_mae: 0.2190\n",
      "Epoch 35/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0148 - mae: 0.0148 - val_loss: 0.2200 - val_mae: 0.2200\n",
      "Epoch 36/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0147 - mae: 0.0147 - val_loss: 0.2244 - val_mae: 0.2244\n",
      "Epoch 37/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0146 - mae: 0.0146 - val_loss: 0.2071 - val_mae: 0.2071\n",
      "Epoch 38/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.2150 - val_mae: 0.2150\n",
      "Epoch 39/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0144 - mae: 0.0144 - val_loss: 0.1914 - val_mae: 0.1914\n",
      "Epoch 40/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.2143 - val_mae: 0.2143\n",
      "Epoch 41/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0142 - mae: 0.0142 - val_loss: 0.2005 - val_mae: 0.2005\n",
      "Epoch 42/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.2049 - val_mae: 0.2049\n",
      "Epoch 43/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0140 - mae: 0.0140 - val_loss: 0.2031 - val_mae: 0.2031\n",
      "Epoch 44/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.1939 - val_mae: 0.1939\n",
      "Epoch 45/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.1902 - val_mae: 0.1902\n",
      "Epoch 46/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0137 - mae: 0.0137 - val_loss: 0.1878 - val_mae: 0.1878\n",
      "Epoch 47/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0136 - mae: 0.0136 - val_loss: 0.1752 - val_mae: 0.1752\n",
      "Epoch 48/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0135 - mae: 0.0135 - val_loss: 0.1873 - val_mae: 0.1873\n",
      "Epoch 49/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0132 - mae: 0.0132 - val_loss: 0.1765 - val_mae: 0.1765\n",
      "Epoch 50/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0130 - mae: 0.0130 - val_loss: 0.1961 - val_mae: 0.1961\n",
      "Epoch 51/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.1858 - val_mae: 0.1858\n",
      "Epoch 52/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0129 - mae: 0.0129 - val_loss: 0.1749 - val_mae: 0.1749\n",
      "Epoch 53/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.1785 - val_mae: 0.1785\n",
      "Epoch 54/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0127 - mae: 0.0127 - val_loss: 0.1692 - val_mae: 0.1692\n",
      "Epoch 55/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0123 - mae: 0.0123 - val_loss: 0.1642 - val_mae: 0.1642\n",
      "Epoch 56/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0122 - mae: 0.0122 - val_loss: 0.1603 - val_mae: 0.1603\n",
      "Epoch 57/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0117 - mae: 0.0117 - val_loss: 0.1611 - val_mae: 0.1611\n",
      "Epoch 58/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0114 - mae: 0.0114 - val_loss: 0.1551 - val_mae: 0.1551\n",
      "Epoch 59/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0111 - mae: 0.0111 - val_loss: 0.1520 - val_mae: 0.1520\n",
      "Epoch 60/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0110 - mae: 0.0110 - val_loss: 0.1464 - val_mae: 0.1464\n",
      "Epoch 61/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0108 - mae: 0.0108 - val_loss: 0.1478 - val_mae: 0.1478\n",
      "Epoch 62/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0109 - mae: 0.0109 - val_loss: 0.1541 - val_mae: 0.1541\n",
      "Epoch 63/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0107 - mae: 0.0107 - val_loss: 0.1513 - val_mae: 0.1513\n",
      "Epoch 64/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0105 - mae: 0.0105 - val_loss: 0.1378 - val_mae: 0.1378\n",
      "Epoch 65/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.1418 - val_mae: 0.1418\n",
      "Epoch 66/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0106 - mae: 0.0106 - val_loss: 0.1421 - val_mae: 0.1421\n",
      "Epoch 67/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.1402 - val_mae: 0.1402\n",
      "Epoch 68/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.1448 - val_mae: 0.1448\n",
      "Epoch 69/200\n",
      "18844/18844 [==============================] - 26s 1ms/step - loss: 0.0104 - mae: 0.0104 - val_loss: 0.1425 - val_mae: 0.1425\n",
      "Epoch 70/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0102 - mae: 0.0102 - val_loss: 0.1401 - val_mae: 0.1401\n",
      "Epoch 71/200\n",
      "18844/18844 [==============================] - 24s 1ms/step - loss: 0.0103 - mae: 0.0103 - val_loss: 0.1353 - val_mae: 0.1353\n",
      "Epoch 72/200\n",
      "18844/18844 [==============================] - 25s 1ms/step - loss: 0.0101 - mae: 0.0101 - val_loss: 0.1422 - val_mae: 0.1422\n",
      "Epoch 73/200\n",
      "18844/18844 [==============================] - 27s 1ms/step - loss: 0.0100 - mae: 0.0100 - val_loss: 0.1345 - val_mae: 0.1345\n",
      "Epoch 74/200\n",
      "18844/18844 [==============================] - 26s 1ms/step - loss: 0.0099 - mae: 0.0099 - val_loss: 0.1409 - val_mae: 0.1409\n",
      "Epoch 75/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0097 - mae: 0.0097 - val_loss: 0.1397 - val_mae: 0.1397\n",
      "Epoch 76/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.1463 - val_mae: 0.1463\n",
      "Epoch 77/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0096 - mae: 0.0096 - val_loss: 0.1392 - val_mae: 0.1392\n",
      "Epoch 78/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.1375 - val_mae: 0.1375\n",
      "Epoch 79/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 80/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.1387 - val_mae: 0.1387\n",
      "Epoch 81/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.1441 - val_mae: 0.1441\n",
      "Epoch 82/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0095 - mae: 0.0095 - val_loss: 0.1374 - val_mae: 0.1374\n",
      "Epoch 83/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.1358 - val_mae: 0.1358\n",
      "Epoch 84/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0094 - mae: 0.0094 - val_loss: 0.1486 - val_mae: 0.1486\n",
      "Epoch 85/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 86/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.1312 - val_mae: 0.1312\n",
      "Epoch 87/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.1387 - val_mae: 0.1387\n",
      "Epoch 88/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.1435 - val_mae: 0.1435\n",
      "Epoch 89/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 90/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.1383 - val_mae: 0.1383\n",
      "Epoch 91/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0093 - mae: 0.0093 - val_loss: 0.1335 - val_mae: 0.1335\n",
      "Epoch 92/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.1377 - val_mae: 0.1377\n",
      "Epoch 93/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.1465 - val_mae: 0.1465\n",
      "Epoch 94/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.1361 - val_mae: 0.1361\n",
      "Epoch 95/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.1425 - val_mae: 0.1425\n",
      "Epoch 96/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.1314 - val_mae: 0.1314\n",
      "Epoch 97/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.1347 - val_mae: 0.1347\n",
      "Epoch 98/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0092 - mae: 0.0092 - val_loss: 0.1383 - val_mae: 0.1383\n",
      "Epoch 99/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1383 - val_mae: 0.1383\n",
      "Epoch 100/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1348 - val_mae: 0.1348\n",
      "Epoch 101/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1423 - val_mae: 0.1423\n",
      "Epoch 102/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1410 - val_mae: 0.1410\n",
      "Epoch 103/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1390 - val_mae: 0.1390\n",
      "Epoch 104/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1426 - val_mae: 0.1426\n",
      "Epoch 105/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1360 - val_mae: 0.1360\n",
      "Epoch 106/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1352 - val_mae: 0.1352\n",
      "Epoch 107/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1415 - val_mae: 0.1415\n",
      "Epoch 108/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1391 - val_mae: 0.1391\n",
      "Epoch 109/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1344 - val_mae: 0.1344\n",
      "Epoch 110/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.1321 - val_mae: 0.1321\n",
      "Epoch 111/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.1375 - val_mae: 0.1375\n",
      "Epoch 112/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1358 - val_mae: 0.1358\n",
      "Epoch 113/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.1352 - val_mae: 0.1352\n",
      "Epoch 114/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.1433 - val_mae: 0.1433\n",
      "Epoch 115/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1406 - val_mae: 0.1406\n",
      "Epoch 116/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1434 - val_mae: 0.1434\n",
      "Epoch 117/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1366 - val_mae: 0.1366\n",
      "Epoch 118/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1307 - val_mae: 0.1307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0091 - mae: 0.0091 - val_loss: 0.1408 - val_mae: 0.1408\n",
      "Epoch 120/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1394 - val_mae: 0.1394\n",
      "Epoch 121/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1373 - val_mae: 0.1373\n",
      "Epoch 122/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1404 - val_mae: 0.1404\n",
      "Epoch 123/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.1462 - val_mae: 0.1462\n",
      "Epoch 124/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0090 - mae: 0.0090 - val_loss: 0.1377 - val_mae: 0.1377\n",
      "Epoch 125/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1347 - val_mae: 0.1347\n",
      "Epoch 126/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1416 - val_mae: 0.1416\n",
      "Epoch 127/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.1342 - val_mae: 0.1342\n",
      "Epoch 128/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1340 - val_mae: 0.1340\n",
      "Epoch 129/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1390 - val_mae: 0.1390\n",
      "Epoch 130/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1371 - val_mae: 0.1371\n",
      "Epoch 131/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1467 - val_mae: 0.1467\n",
      "Epoch 132/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1437 - val_mae: 0.1437\n",
      "Epoch 133/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1400 - val_mae: 0.1400\n",
      "Epoch 134/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0089 - mae: 0.0089 - val_loss: 0.1406 - val_mae: 0.1406\n",
      "Epoch 135/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1411 - val_mae: 0.1411\n",
      "Epoch 136/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1398 - val_mae: 0.1398\n",
      "Epoch 137/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1397 - val_mae: 0.1397\n",
      "Epoch 138/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1448 - val_mae: 0.1448\n",
      "Epoch 139/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1325 - val_mae: 0.1325\n",
      "Epoch 140/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1384 - val_mae: 0.1384\n",
      "Epoch 141/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1364 - val_mae: 0.1364\n",
      "Epoch 142/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1439 - val_mae: 0.1439\n",
      "Epoch 143/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1404 - val_mae: 0.1404\n",
      "Epoch 144/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1433 - val_mae: 0.1433\n",
      "Epoch 145/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0088 - mae: 0.0088 - val_loss: 0.1359 - val_mae: 0.1359\n",
      "Epoch 146/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1391 - val_mae: 0.1391\n",
      "Epoch 147/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1382 - val_mae: 0.1382\n",
      "Epoch 148/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1392 - val_mae: 0.1392\n",
      "Epoch 149/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1377 - val_mae: 0.1377\n",
      "Epoch 150/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1395 - val_mae: 0.1395\n",
      "Epoch 151/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1327 - val_mae: 0.1327\n",
      "Epoch 152/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1378 - val_mae: 0.1378\n",
      "Epoch 153/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1413 - val_mae: 0.1413\n",
      "Epoch 154/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1401 - val_mae: 0.1401\n",
      "Epoch 155/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1417 - val_mae: 0.1417\n",
      "Epoch 156/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1332 - val_mae: 0.1332\n",
      "Epoch 157/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1413 - val_mae: 0.1413\n",
      "Epoch 158/200\n",
      "18844/18844 [==============================] - 34s 2ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1382 - val_mae: 0.1382\n",
      "Epoch 159/200\n",
      "18844/18844 [==============================] - 31s 2ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1370 - val_mae: 0.1370\n",
      "Epoch 160/200\n",
      "18844/18844 [==============================] - 24s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1441 - val_mae: 0.1441\n",
      "Epoch 161/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1377 - val_mae: 0.1377\n",
      "Epoch 162/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1379 - val_mae: 0.1379\n",
      "Epoch 163/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1295 - val_mae: 0.1295\n",
      "Epoch 164/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1600 - val_mae: 0.1600\n",
      "Epoch 165/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1439 - val_mae: 0.1439\n",
      "Epoch 166/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0087 - mae: 0.0087 - val_loss: 0.1379 - val_mae: 0.1379\n",
      "Epoch 167/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1345 - val_mae: 0.1345\n",
      "Epoch 168/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1390 - val_mae: 0.1390\n",
      "Epoch 169/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1364 - val_mae: 0.1364\n",
      "Epoch 170/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1402 - val_mae: 0.1402\n",
      "Epoch 171/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1396 - val_mae: 0.1396\n",
      "Epoch 172/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1387 - val_mae: 0.1387\n",
      "Epoch 173/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1428 - val_mae: 0.1428\n",
      "Epoch 174/200\n",
      "18844/18844 [==============================] - 21s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1427 - val_mae: 0.1427\n",
      "Epoch 175/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1469 - val_mae: 0.1469\n",
      "Epoch 176/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1349 - val_mae: 0.1349\n",
      "Epoch 177/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1375 - val_mae: 0.1375\n",
      "Epoch 178/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1430 - val_mae: 0.1430\n",
      "Epoch 179/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1436 - val_mae: 0.1436\n",
      "Epoch 180/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1342 - val_mae: 0.1342\n",
      "Epoch 181/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1392 - val_mae: 0.1392\n",
      "Epoch 182/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1402 - val_mae: 0.1402\n",
      "Epoch 183/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1310 - val_mae: 0.1310\n",
      "Epoch 184/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1356 - val_mae: 0.1356\n",
      "Epoch 185/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1443 - val_mae: 0.1443\n",
      "Epoch 186/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1301 - val_mae: 0.1301\n",
      "Epoch 187/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1420 - val_mae: 0.1420\n",
      "Epoch 188/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1464 - val_mae: 0.1464\n",
      "Epoch 189/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1382 - val_mae: 0.1382\n",
      "Epoch 190/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1399 - val_mae: 0.1399\n",
      "Epoch 191/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1347 - val_mae: 0.1347\n",
      "Epoch 192/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1497 - val_mae: 0.1497\n",
      "Epoch 193/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0083 - mae: 0.0083 - val_loss: 0.1345 - val_mae: 0.1345\n",
      "Epoch 194/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1340 - val_mae: 0.1340\n",
      "Epoch 195/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1367 - val_mae: 0.1367\n",
      "Epoch 196/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1405 - val_mae: 0.1405\n",
      "Epoch 197/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1398 - val_mae: 0.1398\n",
      "Epoch 198/200\n",
      "18844/18844 [==============================] - 22s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1479 - val_mae: 0.1479\n",
      "Epoch 199/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0085 - mae: 0.0085 - val_loss: 0.1419 - val_mae: 0.1419\n",
      "Epoch 200/200\n",
      "18844/18844 [==============================] - 23s 1ms/step - loss: 0.0086 - mae: 0.0086 - val_loss: 0.1358 - val_mae: 0.1358\n",
      "20938/20938 [==============================] - 15s 702us/step - loss: 0.1365 - mae: 0.1365\n",
      "0.13652417063713074\n",
      "Test loss: 0.13652417063713074\n",
      "Test accuracy: 0.13652417063713074\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelr = build_regression_model(train_rx, train_ry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#預測test\n",
    "pred_ry = modelr.predict(test_rx)\n",
    "pred_ry = pred_ry.flatten()\n",
    "#預測train\n",
    "pred_train_ry = modelr.predict(train_rx)\n",
    "pred_train_ry = pred_train_ry.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test predict: mae:0.1370821365811608, mape:4.692718505859375, rmse:0.26775387100572307\n"
     ]
    }
   ],
   "source": [
    "rain_ry2 = train_ry.copy()\n",
    "train_ry2 = train_ry.values\n",
    "train_ry2 = [float(train_ry2[i]) for i in range(len(train_ry2))]\n",
    "#數值預測指標結果\n",
    "mae = mean_absolute_error(test_ry, pred_ry)\n",
    "mape = mean_absolute_percentage_error(test_ry, pred_ry)\n",
    "rmse = root_mean_squared_error(test_ry, pred_ry)\n",
    "print(f'test predict: mae:{mae}, mape:{mape}, rmse:{rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train predict: mae:0.13652364402152398, mape:4.674554824829102, rmse:0.26718990148744665\n"
     ]
    }
   ],
   "source": [
    "mae_train = mean_absolute_error(train_ry2, pred_train_ry)\n",
    "mape_train = mean_absolute_percentage_error(train_ry2, pred_train_ry)\n",
    "rmse_train = root_mean_squared_error(train_ry2, pred_train_ry)\n",
    "print(f'train predict: mae:{mae_train}, mape:{mape_train}, rmse:{rmse_train}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talos_best(x_train, y_train, x_val, y_val, params):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "    optimizer=params['optimizer'], metrics = ['accuracy',recall_m,precision_m,f1_m])\n",
    "\n",
    "    out = model.fit(x_train, y_train,\n",
    "                              epochs=params['epochs'],  \n",
    "                              batch_size=params['batch_size'],\n",
    "                              validation_data=(x_val, y_val))\n",
    "    return out,model\n",
    "\n",
    "#預測結果模型\n",
    "def build_classification_model(x, y):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "#     sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001), metrics = ['accuracy',recall_m,precision_m,f1_m])\n",
    "\n",
    "    \n",
    "    model_result = model.fit(x, y,\n",
    "                              epochs=200,  \n",
    "                              batch_size=32,\n",
    "                              validation_split=0.33)\n",
    "    score = model.evaluate(x, y, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    plt.plot(model_result.history['accuracy'])\n",
    "    plt.plot(model_result.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left') \n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cy = to_categorical(test_cy)\n",
    "train_cy = to_categorical(train_cy)\n",
    "\n",
    "classification_y =  to_categorical(classification_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14029/14029 [==============================] - 32s 2ms/step - loss: nan - accuracy: 0.2490 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 2/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2499 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 3/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 4/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2513 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 5/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2500 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 6/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2500 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 7/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2492 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 8/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2492 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 9/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 10/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 11/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 12/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 13/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2498 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 14/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2485 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 15/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 16/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2482 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 17/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 18/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 19/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2491 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 20/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 21/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2484 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 22/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2505 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 23/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 24/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2502 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 25/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2514 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 26/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 27/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 28/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2491 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 29/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2498 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 30/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 31/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2485 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 32/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2498 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 33/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2506 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2501 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 35/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 36/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2499 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 37/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2499 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 38/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 39/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2496 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 40/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2492 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 41/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2498 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 42/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2502 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 43/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2512 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 44/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2492 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 45/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2492 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 46/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 47/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 48/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2485 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 49/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2500 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 50/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2475 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 51/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 52/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2485 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 53/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2501 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 54/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2492 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 55/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2502 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 56/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 57/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 58/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2500 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 59/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2502 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 60/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2486 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 61/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2496 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 62/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 63/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2500 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 64/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 65/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 66/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2498 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 68/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2496 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 69/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2500 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 70/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2502 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 71/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2488 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 72/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2498 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 73/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2508 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 74/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 75/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 76/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2489 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 77/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 78/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 79/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2490 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 80/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2482 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 81/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 82/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 83/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2505 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 84/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2501 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 85/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2499 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 86/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2500 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 87/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2484 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 88/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2502 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 89/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2511 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 90/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2496 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 91/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 92/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 93/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 94/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 95/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2498 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 96/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2498 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 97/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 98/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2496 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 99/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2496 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2498 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 101/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2508 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 102/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 103/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2483 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 104/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2490 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 105/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2489 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 106/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2490 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 107/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2500 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 108/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 109/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2501 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 110/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 111/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2489 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 112/200\n",
      "14029/14029 [==============================] - 3624s 258ms/step - loss: nan - accuracy: 0.2501 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 113/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2490 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 114/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 115/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2501 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 116/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 117/200\n",
      "14029/14029 [==============================] - 26s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 118/200\n",
      "14029/14029 [==============================] - 40s 3ms/step - loss: nan - accuracy: 0.2491 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 119/200\n",
      "14029/14029 [==============================] - 33s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 120/200\n",
      "14029/14029 [==============================] - 31s 2ms/step - loss: nan - accuracy: 0.2490 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 121/200\n",
      "14029/14029 [==============================] - 31s 2ms/step - loss: nan - accuracy: 0.2503 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 122/200\n",
      "14029/14029 [==============================] - 33s 2ms/step - loss: nan - accuracy: 0.2492 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 123/200\n",
      "14029/14029 [==============================] - 33s 2ms/step - loss: nan - accuracy: 0.2499 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 124/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2496 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 125/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2499 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 126/200\n",
      "14029/14029 [==============================] - 31s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 127/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2488 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 128/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2490 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 129/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2499 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 130/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2485 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 131/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 132/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2482 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 134/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 135/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2486 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 136/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 137/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2504 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 138/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 139/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 140/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2496 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 141/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2492 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 142/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2491 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 143/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 144/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2512 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 145/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2489 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 146/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 147/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2504 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 148/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 149/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2486 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 150/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 151/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 152/200\n",
      "14029/14029 [==============================] - 31s 2ms/step - loss: nan - accuracy: 0.2489 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 153/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2503 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 154/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2476 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 155/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2498 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 156/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2496 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 157/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 158/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2489 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 159/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2492 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 160/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 161/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2491 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 162/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 163/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2485 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 164/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 165/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2509 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2478 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 167/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2484 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 168/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 169/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 170/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2501 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 171/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 172/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2503 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 173/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2489 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 174/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2498 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 175/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2491 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 176/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2492 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 177/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2492 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 178/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2489 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 179/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2491 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 180/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2494 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 181/200\n",
      "14029/14029 [==============================] - 27s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 182/200\n",
      "14029/14029 [==============================] - 33s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 183/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2503 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 184/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2501 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 185/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2498 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 186/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2490 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 187/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2495 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 188/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2504 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 189/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2500 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 190/200\n",
      "14029/14029 [==============================] - 31s 2ms/step - loss: nan - accuracy: 0.2509 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 191/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2486 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 192/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2497 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 193/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2506 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 194/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2498 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 195/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2490 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 196/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2493 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 197/200\n",
      "14029/14029 [==============================] - 28s 2ms/step - loss: nan - accuracy: 0.2488 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 198/200\n",
      "14029/14029 [==============================] - 29s 2ms/step - loss: nan - accuracy: 0.2505 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2505 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "Epoch 200/200\n",
      "14029/14029 [==============================] - 30s 2ms/step - loss: nan - accuracy: 0.2508 - recall_m: nan - precision_m: nan - f1_m: nan - val_loss: nan - val_accuracy: 0.2507 - val_recall_m: nan - val_precision_m: nan - val_f1_m: nan\n",
      "20938/20938 [==============================] - 22s 876us/step - loss: nan - accuracy: 0.2499 - recall_m: nan - precision_m: nan - f1_m: nan\n",
      "Test loss: 0.24992425739765167\n",
      "Test accuracy: nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelr = build_classification_model(train_rx, train_ry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
